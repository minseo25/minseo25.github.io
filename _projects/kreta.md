---
layout: page
title: KRETA
description: Korean Text-Rich VQA Benchmark and fine-tuned VLM
img: assets/img/kreta2.png
importance: 2
category: work
related_publications: false
---

<ul class="list-unstyled">
  <li>
    <i class="fa-solid fa-calendar mr-1"></i>
    <b>Period</b>: Oct 2024 â€” Feb 2025
  </li>
  <li>
    <i class="fa-solid fa-screwdriver-wrench mr-1"></i>
    <b>Tools</b>: PyTorch
  </li>
  <li class="mt-1">
    <i class="fa-brands fa-github mr-1"></i>
    <b>GitHub</b>:
    <ul class="mb-0">
      <li><a href="https://github.com/tabtoyou/KRETA" target="_blank" rel="noopener noreferrer">Benchmark</a></li>
      <li><a href="https://github.com/minseo25/KOVA" target="_blank" rel="noopener noreferrer">Fine-tuned Demo (KOVA)</a></li>
    </ul>
  </li>
  <li class="mt-1">
    <i class="fa-solid fa-link mr-1"></i>
    <b>URL</b>:
    N/A
  </li>
</ul>

---

<ul>
  <li>Collected Korean text-rich image datasets and fine-tuned LLaVA-OneVision to strengthen Korean capability.</li>
  <li>Built an end-to-end generation pipeline and released a high-quality Korean text-rich VQA benchmark.</li>
</ul>
